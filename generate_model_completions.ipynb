{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialize import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44a3081a9aa44df9a855364671ada3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "### Load the model\n",
    "\n",
    "base_model_path: str = \"meta-llama/Meta-Llama-3-8B-Instruct\"#\"meta-llama/Llama-2-13b-chat-hf\"\n",
    "model_path=base_model_path\n",
    "###model_path=\"cackerman/llama2_13b_chat_projection_tune_neg_in\"\n",
    "device: str = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "model = load_model(model_path, base_model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion_prompts(filename, comp_file=None, base = False):\n",
    "    starts = load_from_json(filename)\n",
    "    if comp_file: completions = load_from_json(comp_file)\n",
    "    completion_prompts=[]\n",
    "    for start in starts:\n",
    "        if base:\n",
    "            prompt = LLAMA3_CONTINUATION_BASE_PROMPT_TEMPLATE.format(user_prompt=start['text']).strip()\n",
    "        else:\n",
    "            if comp_file:\n",
    "                index = next((i for i, d in enumerate(completions) if d['id'] == start['id']), -1)\n",
    "                #textarr = model.tokenizer.encode(completions[index]['text'], return_tensors=\"pt\")[0]\n",
    "                textarr = completions[index]['text'].split()\n",
    "                wdct = round(len(textarr)/10)*10\n",
    "                prompt = LLAMA3_CONTINUATION_PROMPT_TEMPLATE.format(system_prompt=CONTINUATION_SYSTEM_PROMPT_TEMPLATE.format(wordcount=wdct),user_prompt=start['text']).strip()### without the strip I sometimes get null (from the chat model) or garbage (from the base model) output\n",
    "            else:\n",
    "                prompt = LLAMA3_CONTINUATION_PROMPT_TEMPLATE.format(system_prompt=CONTINUATION_SYSTEM_PROMPT,user_prompt=start['text']).strip()### without the strip I sometimes get null (from the chat model) or garbage (from the base model) output\n",
    "        completion_prompts.append({'id': start['id'], 'source': start['source'], 'text': prompt})\n",
    "    return completion_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'id633',\n",
       "  'source': 'forum',\n",
       "  'text': \"<|start_header_id|>system<|end_header_id|>\\n\\nYou are an engine that repeats given text and writes a natural continuation of it. Your task is to repeat the text given by the user and continue it. Your generated text should have at least 400 words.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYusunoha: Question regarding diffusing a led strip on a plaque.\\n[removed]\\nWolfiesden: Well, I would have to ask first, what is the purpose of the light?\\n\\nAre you adding it to illuminate the animal head?  Are you adding it as a decoration?  Trying to make it an eye catcher?\\n\\nJust remember that anyone looking at the head will be staring into the light which may make it less appealing to look at rather than more appealing if you end up putting it on the front like your image shows.\\n\\nNow, if you are going the route of lighting the object, then you need to use some sort of directed light that is at least partly shielded from the person viewing it (so they don't look like a deer in headlights either).\\n\\nIf you are going decoration aspect, consider NOT putting it on the front.  Put it around the edge<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nYusunoha: Question regarding diffusing a led strip on a plaque.\\n[removed]\\nWolfiesden: Well, I would have to ask first, what is the purpose of the light?\\n\\nAre you adding it to illuminate the animal head?  Are you adding it as a decoration?  Trying to make it an eye catcher?\\n\\nJust remember that anyone looking at the head will be staring into the light which may make it less appealing to look at rather than more appealing if you end up putting it on the front like your image shows.\\n\\nNow, if you are going the route of lighting the object, then you need to use some sort of directed light that is at least partly shielded from the person viewing it (so they don't look like a deer in headlights either).\\n\\nIf you are going decoration aspect, consider NOT putting it on the front.  Put it around the edge\"},\n",
       " {'id': 'id1131',\n",
       "  'source': 'abstracts',\n",
       "  'text': '<|start_header_id|>system<|end_header_id|>\\n\\nYou are an engine that repeats given text and writes a natural continuation of it. Your task is to repeat the text given by the user and continue it. Your generated text should have at least 240 words.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThe origin of quasiconformal mappings, like that of conformal mappings, can be traced back to old cartography where the basic problem was the search for mappings from the sphere onto the plane with minimal deviation from conformality, subject to certain conditions which were made precise. In this paper, we survey the development of cartography, highlighting the main ideas that are related to quasiconformality. Some of these ideas were completely ignored in the previous historical surveys on quasiconformal mappings. We then survey early quasiconformal theory in the works of Gr\\\\\"otzsch, Lavrentieff, Ahlfors and Teichm\\\\\"uller, which are the 20th-century founders of the theory. The period we consider starts with Claudius Ptolemy (c. 100--170 A.D.) and ends with Oswald Teichm\\\\\"uller (1913--1943). We<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe origin of quasiconformal mappings, like that of conformal mappings, can be traced back to old cartography where the basic problem was the search for mappings from the sphere onto the plane with minimal deviation from conformality, subject to certain conditions which were made precise. In this paper, we survey the development of cartography, highlighting the main ideas that are related to quasiconformality. Some of these ideas were completely ignored in the previous historical surveys on quasiconformal mappings. We then survey early quasiconformal theory in the works of Gr\\\\\"otzsch, Lavrentieff, Ahlfors and Teichm\\\\\"uller, which are the 20th-century founders of the theory. The period we consider starts with Claudius Ptolemy (c. 100--170 A.D.) and ends with Oswald Teichm\\\\\"uller (1913--1943). We'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_prompts=generate_completion_prompts('./starts_full/starts_train.json', comp_file='./completions_full/completions_human_train.json', base=False)\n",
    "completion_prompts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "  1%|          | 5/500 [02:07<3:18:06, 24.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 10 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/500 [02:55<2:36:07, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad output at  id1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/500 [03:49<3:12:55, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 20 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/500 [06:40<3:53:40, 28.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad output at  id445\n",
      "Completed 30 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 20/500 [08:41<3:18:54, 24.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 40 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 25/500 [11:02<3:36:41, 27.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 50 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 30/500 [12:54<2:57:08, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 60 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 35/500 [15:03<3:30:26, 27.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 70 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 39/500 [16:32<2:52:15, 22.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad output at  id587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 40/500 [16:51<2:43:05, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 80 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 45/500 [18:40<2:35:12, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 90 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 50/500 [20:36<2:58:40, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 55/500 [23:01<3:47:34, 30.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 110 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 60/500 [25:08<2:57:22, 24.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 120 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 65/500 [26:50<2:33:09, 21.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 130 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 70/500 [30:18<4:18:29, 36.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 140 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 75/500 [32:30<3:23:48, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 150 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 80/500 [34:38<3:28:44, 29.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 160 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 85/500 [36:31<2:51:15, 24.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 170 rows out of 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 86/500 [37:03<3:05:48, 26.93s/it]"
     ]
    }
   ],
   "source": [
    "def do_batch_decode(generated_tokens, input_ids, tokenizer):\n",
    "    batch_size = generated_tokens.shape[0]\n",
    "    start_indices = input_ids.shape[1]\n",
    "    max_len = generated_tokens.shape[1] - start_indices\n",
    "    tokens_to_decode = torch.full((batch_size, max_len), tokenizer.pad_token_id, dtype=torch.long)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        len_to_decode = generated_tokens.shape[1] - input_ids.shape[1]\n",
    "        tokens_to_decode[i, :len_to_decode] = generated_tokens[i, input_ids.shape[1]:]\n",
    "    \n",
    "    return tokenizer.batch_decode(tokens_to_decode, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    \n",
    "def generate_completions(model, model_name, prompts, batch_size=4, split=\"train\"):\n",
    "    dir_name = \"completions_longer\"\n",
    "    outputfile = f\"completions_{model_name}_{split}\"\n",
    "    filename = f\"{dir_name}/{outputfile}.json\"\n",
    "    partial_filename = f\"{dir_name}/{outputfile}_partial.json\"    \n",
    "\n",
    "    results = []    \n",
    "    if os.path.exists(filename) or os.path.exists(partial_filename):\n",
    "        results_tmp = load_from_json(filename) if os.path.exists(filename) else load_from_json(partial_filename)\n",
    "        results = [result for result in results_tmp if result['text'] != \"\"]\n",
    "        existing_combinations = {(result['id'], result['source']) for result in results}\n",
    "        prompts = [q for q in prompts if (q['id'], q['source']) not in existing_combinations]\n",
    "        if prompts == []:\n",
    "            print(f\"All data in {filename} has been processed. Exiting.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"Processing new data not in {filename}\")\n",
    "    initlenresults = len(results)\n",
    "\n",
    "    model.eval()\n",
    "    model.tokenizer.padding_side=\"left\"\n",
    "    sampling_kwargs={\"use_cache\": True, \"pad_token_id\": model.tokenizer.pad_token_id, \"max_new_tokens\": 1500, \"do_sample\": True}\n",
    "\n",
    "    encodelens=[]\n",
    "    for i in tqdm(range(initlenresults, initlenresults+len(prompts), batch_size)):\n",
    "        #print(f\"Processing batch {i} to {i + batch_size}\")\n",
    "        batch = prompts[i-initlenresults:min(i-initlenresults+batch_size,len(prompts))]\n",
    "        input_texts = [item[f\"text\"] for item in batch] \n",
    "        inputs = model.tokenizer(input_texts, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        #encodelens.extend([len(input['input_ids']) for input in inputs])\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(**inputs, **sampling_kwargs)\n",
    "\n",
    "        output = do_batch_decode(output_ids, inputs['input_ids'], model.tokenizer)\n",
    "\n",
    "        for j, item in enumerate(batch):\n",
    "            if len(results) <= i + j:#if this is your first time processing this input\n",
    "                results.append({\"id\": item[\"id\"], \"source\": item[\"source\"]})\n",
    "            \n",
    "            result = results[i + j]\n",
    "            result[\"text\"] = output[j]\n",
    "            if output[j] == \"\": print(\"Bad output at \",item[\"id\"])\n",
    "            encodelens.append(len(inputs['input_ids'][j]))\n",
    "            \n",
    "        if (i-initlenresults + batch_size) % 10 == 0 or (i-initlenresults + batch_size) >= len(prompts):\n",
    "            print(f\"Completed {i-initlenresults + batch_size} rows out of {len(prompts)}\")\n",
    "            save_to_json(results, partial_filename)\n",
    "\n",
    "    save_to_json(results, filename)\n",
    "    return encodelens\n",
    "\n",
    "encodelens=generate_completions(model=model, model_name=\"llama3_8bbase\", prompts=completion_prompts, batch_size=2, split=\"train\")\n",
    "if encodelens: print(\"Max encodelens=\",max(encodelens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "483\n",
      " will also discuss the contributions of other mathematicians and cartographers who played a significant role in the development of quasiconformal mappings.\n",
      "\n",
      "Ptolemy's work, \"Geographia\", is a fundamental source of information on ancient cartography and its methods. He developed a system of coordinates and a method for projecting the curved surface of the Earth onto a flat plane. His work had a significant impact on the development of cartography and was widely used for many centuries. The development of quasiconformal mappings can be seen as an extension of Ptolemy's work, as it deals with the problem of projecting the curved surface of the sphere onto a flat plane while preserving the angles and shapes of the original surface.\n",
      "\n",
      "In the 17th and 18th centuries, cartographers such as Gerardus Mercator and Johann Bayer developed new methods for projecting the Earth's surface onto a flat plane. Mercator's projection, which is still widely used today, is a conformal mapping that preserves angles and shapes, but it distorts the size and shape of the original surface. Bayer's projection, on the other hand, is a non-conformal mapping that preserves the size and shape of the original surface, but distorts the angles and shapes.\n",
      "\n",
      "The development of quasiconformal mappings can be seen as an attempt to find a compromise between these two approaches. Quasiconformal mappings preserve the angles and shapes of the original surface, but they also allow for some distortion, which makes them more practical for use in cartography. The development of quasiconformal mappings was driven by the need for more accurate and practical methods for projecting the Earth's surface onto a flat plane.\n",
      "\n",
      "In the 20th century, mathematicians such as Gr\\\"otzsch, Lavrentieff, Ahlfors and Teichm\\\"uller made significant contributions to the development of quasiconformal mappings. Gr\\\"otzsch's work on the Riemann mapping theorem laid the foundation for the development of quasiconformal mappings, while Lavrentieff's work on the theory of quasiconformal mappings provided a new approach to the problem. Ahlfors and Teichm\\\"uller's work on the theory of quasiconformal mappings and its applications to complex analysis and geometry further developed the theory and its applications.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "#, \"pad_token_id\": model.tokenizer.pad_token_id\n",
    "model.tokenizer.padding_side=\"left\"\n",
    "index = 1#next((i for i, d in enumerate(completion_prompts) if d['id'] == 'id1522'), -1)\n",
    "sampling_kwargs={\"use_cache\": True, \"pad_token_id\": model.tokenizer.pad_token_id, \"max_new_tokens\": 1500, \"do_sample\": True}#, \"repetition_penalty\": 1.5, \"penalty_alpha\": 0.6, \"top_k\": 4}#, \"no_repeat_ngram_size\": 4}\n",
    "#input_ids = model.tokenizer.encode(completion_prompts[3]['text'], return_tensors=\"pt\").to(model.device)\n",
    "inputs = model.tokenizer(completion_prompts[index]['text'], return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs,**sampling_kwargs)[0]\n",
    "output=model.tokenizer.decode(outputs[len(inputs['input_ids'][0]):])\n",
    "print(len(output.split()))\n",
    "print(len(outputs)-len(inputs['input_ids'][0]))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_header_id|>system<|end_header_id|>\\n\\nYou are an engine that repeats given text and writes a natural continuation of it. Your task is to repeat the text given by the user and continue it. Your generated text should have at least 240 words.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThe origin of quasiconformal mappings, like that of conformal mappings, can be traced back to old cartography where the basic problem was the search for mappings from the sphere onto the plane with minimal deviation from conformality, subject to certain conditions which were made precise. In this paper, we survey the development of cartography, highlighting the main ideas that are related to quasiconformality. Some of these ideas were completely ignored in the previous historical surveys on quasiconformal mappings. We then survey early quasiconformal theory in the works of Gr\\\\\"otzsch, Lavrentieff, Ahlfors and Teichm\\\\\"uller, which are the 20th-century founders of the theory. The period we consider starts with Claudius Ptolemy (c. 100--170 A.D.) and ends with Oswald Teichm\\\\\"uller (1913--1943). We<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe origin of quasiconformal mappings, like that of conformal mappings, can be traced back to old cartography where the basic problem was the search for mappings from the sphere onto the plane with minimal deviation from conformality, subject to certain conditions which were made precise. In this paper, we survey the development of cartography, highlighting the main ideas that are related to quasiconformality. Some of these ideas were completely ignored in the previous historical surveys on quasiconformal mappings. We then survey early quasiconformal theory in the works of Gr\\\\\"otzsch, Lavrentieff, Ahlfors and Teichm\\\\\"uller, which are the 20th-century founders of the theory. The period we consider starts with Claudius Ptolemy (c. 100--170 A.D.) and ends with Oswald Teichm\\\\\"uller (1913--1943). We'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_prompts[index]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
